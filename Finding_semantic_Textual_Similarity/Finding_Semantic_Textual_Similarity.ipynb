{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finding Semantic Textual Similarity.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SnIb5DHP4Gz"
      },
      "source": [
        "##Finding Semantic Textual Similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u43s4GbPQp8F"
      },
      "source": [
        "\n",
        "*   0 means highly similar\n",
        "*   1 means higly dissimilar\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2BfgfeUQKW-"
      },
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "import collections\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer  # For Lemmetization of words\n",
        "from nltk.corpus import stopwords  # Load list of stopwords\n",
        "from nltk import word_tokenize # Convert paragraph in tokens\n",
        "\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "from gensim.models import word2vec # For represent words in vectors\n",
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "QMpoLzazRGji",
        "outputId": "7128645b-4651-4158-a771-26d02bd56846"
      },
      "source": [
        "# importing dataset \n",
        "data = pd.read_csv(\"Text_Similarity_Dataset.csv\")\n",
        "print(\"Shape of data : \", data.shape)\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data :  (4023, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique_ID</th>\n",
              "      <th>text1</th>\n",
              "      <th>text2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>savvy searchers fail to spot ads internet sear...</td>\n",
              "      <td>newcastle 2-1 bolton kieron dyer smashed home ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>millions to miss out on the net by 2025  40% o...</td>\n",
              "      <td>nasdaq planning $100m share sale the owner of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>young debut cut short by ginepri fifteen-year-...</td>\n",
              "      <td>ruddock backs yapp s credentials wales coach m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>diageo to buy us wine firm diageo  the world s...</td>\n",
              "      <td>mci shares climb on takeover bid shares in us ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>be careful how you code a new european directi...</td>\n",
              "      <td>media gadgets get moving pocket-sized devices ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unique_ID  ...                                              text2\n",
              "0          0  ...  newcastle 2-1 bolton kieron dyer smashed home ...\n",
              "1          1  ...  nasdaq planning $100m share sale the owner of ...\n",
              "2          2  ...  ruddock backs yapp s credentials wales coach m...\n",
              "3          3  ...  mci shares climb on takeover bid shares in us ...\n",
              "4          4  ...  media gadgets get moving pocket-sized devices ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CKOch6GRsC2",
        "outputId": "dea6200b-7742-4304-fb1a-9b59e516780f"
      },
      "source": [
        "#checking if there are null values\n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unique_ID    0\n",
              "text1        0\n",
              "text2        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv6XtfiJR3XE"
      },
      "source": [
        "#Data preprocessing \n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gczefutrTbib",
        "outputId": "28a481d5-9b3d-4f89-e81a-67a123ba07c6"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSPcN5CKSG7n",
        "outputId": "04b41748-4ecc-400a-c5fa-ae590c64a801"
      },
      "source": [
        "preprocessed_text1 = []\n",
        "\n",
        "\n",
        "for sentance in tqdm(data['text1'].values):\n",
        "    sent = decontracted(sentance)\n",
        "    sent = sent.replace('\\\\r', ' ')\n",
        "    sent = sent.replace('\\\\\"', ' ')\n",
        "    sent = sent.replace('\\\\n', ' ')\n",
        "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
        "\n",
        "    sent = ' '.join(e for e in sent.split() if e not in stopwords.words('english'))\n",
        "    preprocessed_text1.append(sent.lower().strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4023/4023 [03:18<00:00, 20.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "yDPrwNvYSMsV",
        "outputId": "c21b47f1-4011-4f34-e781-db1d36366e58"
      },
      "source": [
        "# merging preprocessed_text1 in data\n",
        "data['text1'] = preprocessed_text1\n",
        "data.head(5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique_ID</th>\n",
              "      <th>text1</th>\n",
              "      <th>text2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>savvy searchers fail spot ads internet search ...</td>\n",
              "      <td>newcastle 2-1 bolton kieron dyer smashed home ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>millions miss net 2025 40 uk population still ...</td>\n",
              "      <td>nasdaq planning $100m share sale the owner of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>young debut cut short ginepri fifteen year old...</td>\n",
              "      <td>ruddock backs yapp s credentials wales coach m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>diageo buy us wine firm diageo world biggest s...</td>\n",
              "      <td>mci shares climb on takeover bid shares in us ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>careful code new european directive could put ...</td>\n",
              "      <td>media gadgets get moving pocket-sized devices ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unique_ID  ...                                              text2\n",
              "0          0  ...  newcastle 2-1 bolton kieron dyer smashed home ...\n",
              "1          1  ...  nasdaq planning $100m share sale the owner of ...\n",
              "2          2  ...  ruddock backs yapp s credentials wales coach m...\n",
              "3          3  ...  mci shares climb on takeover bid shares in us ...\n",
              "4          4  ...  media gadgets get moving pocket-sized devices ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cttWkf1sTsPC",
        "outputId": "a9e3161b-f2f6-4e8b-d163-fd9bbe025c62"
      },
      "source": [
        "from tqdm import tqdm\n",
        "preprocessed_text2 = []\n",
        "\n",
        "# tqdm is for printing the status bar\n",
        "for sentance in tqdm(data['text2'].values):\n",
        "    sent = decontracted(sentance)\n",
        "    sent = sent.replace('\\\\r', ' ')\n",
        "    sent = sent.replace('\\\\\"', ' ')\n",
        "    sent = sent.replace('\\\\n', ' ')\n",
        "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
        "   \n",
        "    sent = ' '.join(e for e in sent.split() if e not in stopwords.words('english'))\n",
        "    preprocessed_text2.append(sent.lower().strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4023/4023 [03:17<00:00, 20.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "nOUdg8TDT8dh",
        "outputId": "855a4f76-52f6-4e3c-d1fd-1a5133756aa5"
      },
      "source": [
        "# merging preprocessed_text2 in data\n",
        "\n",
        "data['text2'] = preprocessed_text2\n",
        "\n",
        "data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique_ID</th>\n",
              "      <th>text1</th>\n",
              "      <th>text2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>savvy searchers fail spot ads internet search ...</td>\n",
              "      <td>newcastle 2 1 bolton kieron dyer smashed home ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>millions miss net 2025 40 uk population still ...</td>\n",
              "      <td>nasdaq planning 100m share sale owner technolo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>young debut cut short ginepri fifteen year old...</td>\n",
              "      <td>ruddock backs yapp credentials wales coach mik...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unique_ID  ...                                              text2\n",
              "0          0  ...  newcastle 2 1 bolton kieron dyer smashed home ...\n",
              "1          1  ...  nasdaq planning 100m share sale owner technolo...\n",
              "2          2  ...  ruddock backs yapp credentials wales coach mik...\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y26vxibuUB4k"
      },
      "source": [
        "def word_tokenizer(text):\n",
        "            #tokenizes and stems the text\n",
        "            tokens = word_tokenize(text)\n",
        "            lemmatizer = WordNetLemmatizer() \n",
        "            tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "            return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWUHtOlAUFHt"
      },
      "source": [
        "\n",
        "# Loading pre_trained Google News Vectors \n",
        "\n",
        "wordmodelfile=\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "wordmodel= gensim.models.KeyedVectors.load_word2vec_format(wordmodelfile, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-ovCwkVaNTv",
        "outputId": "0b570535-fbde-49b1-932b-98a274efb5ab"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypdVcNWIUNZP"
      },
      "source": [
        "#creating list to store similarity score\n",
        "similarity = [] # List for store similarity score\n",
        "\n",
        "\n",
        "\n",
        "for ind in data.index:\n",
        "    \n",
        "        s1 = data['text1'][ind]\n",
        "        s2 = data['text2'][ind]\n",
        "        \n",
        "        if s1==s2:\n",
        "                 similarity.append(0.0) # 0 means highly similar\n",
        "                \n",
        "        else:   \n",
        "\n",
        "            s1words = word_tokenizer(s1)\n",
        "            s2words = word_tokenizer(s2)\n",
        "            \n",
        "           \n",
        "            \n",
        "            vocab = wordmodel.vocab #the vocabulary considered in the word embeddings\n",
        "            \n",
        "            if len(s1words and s2words)==0:\n",
        "                    similarity.append(1.0)\n",
        "\n",
        "            else:\n",
        "                \n",
        "                for word in s1words.copy(): #remove sentence words not found in the vocab\n",
        "                    if (word not in vocab):\n",
        "                           \n",
        "                            \n",
        "                            s1words.remove(word)\n",
        "                        \n",
        "                    \n",
        "                for word in s2words.copy(): #idem\n",
        "\n",
        "                    if (word not in vocab):\n",
        "                           \n",
        "                            s2words.remove(word)\n",
        "                            \n",
        "                            \n",
        "                similarity.append((1-wordmodel.n_similarity(s1words, s2words))) # as it is given 1 means highly dissimilar & 0 means highly similar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "CpXhZmTjUVsl",
        "outputId": "3de493bb-f0f0-49a2-f94d-c354a1f8194e"
      },
      "source": [
        "#arrangement of data \n",
        "final_score = pd.DataFrame({'Unique_ID':data.Unique_ID,\n",
        "                     'Similarity_score':similarity})\n",
        "final_score.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique_ID</th>\n",
              "      <th>Similarity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.389471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.292066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.272890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.184955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.171677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.249288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.319132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.152613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.209360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.098709</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unique_ID  Similarity_score\n",
              "0          0          0.389471\n",
              "1          1          0.292066\n",
              "2          2          0.272890\n",
              "3          3          0.184955\n",
              "4          4          0.171677\n",
              "5          5          0.249288\n",
              "6          6          0.319132\n",
              "7          7          0.152613\n",
              "8          8          0.209360\n",
              "9          9          0.098709"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnbEA4rJUeGk"
      },
      "source": [
        "#saving dataframe to csv file \n",
        "final_score.to_csv('Solution.csv',index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kQXjouQVnhC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}